{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running HMMER and getting dbCAN output.\n",
    "\n",
    "While you can get dbCAN predictions for a proteome (or predicted proteome) using their web interface (<http://csbl.bmb.uga.edu/dbCAN/annotate.php>), it might be easier to run the search locally if you have a lot of sequences or multiple proteomes to process.\n",
    "\n",
    "Here I go through this process of getting dbCAN formatted output in preparation for the training of CATAStrophy.\n",
    "Note that although I am using a jupyter notebook, the actual code is run only in bash `%%magic` cells meaning that you could just copy-paste into your terminal.\n",
    "\n",
    "To rerun these steps you'll need to be running a UNIX-style command line (this was performed in Fedora 25, but it should be fine in Linux/MacOS), and you'll need [HMMER](http://hmmer.org/) installed (we used v3.1b2) and some version of perl (included in most linux distros; this is used in dbCANs output parser script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# TODAY = \"20180324\" \n",
    "TODAY = datetime.datetime.utcnow().strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dbCAN\n",
    "\n",
    "First we need to download and prepare the dbCAN HMMs.\n",
    "We'll also need to download the parser script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/darcyabjones/Libs/catastrophy/notebooks\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Make sure that you are working in a directory that you can safely work in!\n",
    "\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ./data\n",
    "\n",
    "# Comment out any versions that you don't want\n",
    "# Here we download multiple versions to develop models for each version.\n",
    "wget -qc -P ./data http://csbl.bmb.uga.edu/dbCAN/download/dbCAN-fam-HMMs.txt.v4\n",
    "wget -qc -P ./data http://csbl.bmb.uga.edu/dbCAN/download/dbCAN-fam-HMMs.txt.v5\n",
    "wget -qc -P ./data http://csbl.bmb.uga.edu/dbCAN/download/dbCAN-fam-HMMs.txt.v6\n",
    "wget -qc -P ./data http://cys.bios.niu.edu/dbCAN2/download/Databases/dbCAN-HMMdb-V7.txt\n",
    "\n",
    "wget -qc -P ./data http://csbl.bmb.uga.edu/dbCAN/download/hmmscan-parser.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `-q` flag to wget just suppresses the output of wget so that it doesn't clog up the notebook.\n",
    "The files are now in the 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbCAN-fam-HMMs.txt.v4  dbCAN-fam-HMMs.txt.v6  hmmscan-parser.sh\r\n",
      "dbCAN-fam-HMMs.txt.v5  dbCAN-HMMdb-V7.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we downloaded multiple specific versions of the database.\n",
    "CATAStrophy won't necessarily work correctly with future versions of the database unless we retrain the models.\n",
    "\n",
    "Next we need to create a HMMER formatted database from the .txt file we downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working...    done.\n",
      "Pressed and indexed 345 HMMs (345 names).\n",
      "Models pressed into binary file:   ./data/dbCAN-fam-HMMs.txt.v4.h3m\n",
      "SSI index for binary model file:   ./data/dbCAN-fam-HMMs.txt.v4.h3i\n",
      "Profiles (MSV part) pressed into:  ./data/dbCAN-fam-HMMs.txt.v4.h3f\n",
      "Profiles (remainder) pressed into: ./data/dbCAN-fam-HMMs.txt.v4.h3p\n",
      "Working...    done.\n",
      "Pressed and indexed 360 HMMs (360 names and 1 accessions).\n",
      "Models pressed into binary file:   ./data/dbCAN-fam-HMMs.txt.v5.h3m\n",
      "SSI index for binary model file:   ./data/dbCAN-fam-HMMs.txt.v5.h3i\n",
      "Profiles (MSV part) pressed into:  ./data/dbCAN-fam-HMMs.txt.v5.h3f\n",
      "Profiles (remainder) pressed into: ./data/dbCAN-fam-HMMs.txt.v5.h3p\n",
      "Working...    done.\n",
      "Pressed and indexed 585 HMMs (585 names and 1 accessions).\n",
      "Models pressed into binary file:   ./data/dbCAN-fam-HMMs.txt.v6.h3m\n",
      "SSI index for binary model file:   ./data/dbCAN-fam-HMMs.txt.v6.h3i\n",
      "Profiles (MSV part) pressed into:  ./data/dbCAN-fam-HMMs.txt.v6.h3f\n",
      "Profiles (remainder) pressed into: ./data/dbCAN-fam-HMMs.txt.v6.h3p\n",
      "Working...    done.\n",
      "Pressed and indexed 607 HMMs (607 names and 9 accessions).\n",
      "Models pressed into binary file:   ./data/dbCAN-HMMdb-V7.txt.h3m\n",
      "SSI index for binary model file:   ./data/dbCAN-HMMdb-V7.txt.h3i\n",
      "Profiles (MSV part) pressed into:  ./data/dbCAN-HMMdb-V7.txt.h3f\n",
      "Profiles (remainder) pressed into: ./data/dbCAN-HMMdb-V7.txt.h3p\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# the rm is just here so I can run the notebook without errors\n",
    "rm -f ./data/dbCAN-fam-HMMs.txt.v4.*\n",
    "hmmpress ./data/dbCAN-fam-HMMs.txt.v4\n",
    "\n",
    "rm -f ./data/dbCAN-fam-HMMs.txt.v5.*\n",
    "hmmpress ./data/dbCAN-fam-HMMs.txt.v5\n",
    "\n",
    "rm -f ./data/dbCAN-fam-HMMs.txt.v6.*\n",
    "hmmpress ./data/dbCAN-fam-HMMs.txt.v6\n",
    "\n",
    "rm -f ./data/dbCAN-HMMdb-V7.txt.*\n",
    "hmmpress ./data/dbCAN-HMMdb-V7.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running HMMER\n",
    "\n",
    "Now that the database is ready, we can process our sequences.\n",
    "This is pretty easily done with the command:\n",
    "\n",
    "```bash\n",
    "hmmscan --domtblout my_seqs_hmmer.csv ./data/dbCAN-fam-HMMs.txt my_seqs.fasta > my_seqs_hmmer.txt\n",
    "```\n",
    "\n",
    "The native dbCAN script uses the \"domain table\" (provided by `--domtblout`) as input, which is a much more friendly space-delimited format.\n",
    "The txt output is the raw hmmer output. It is a lot more information rich but also harder to parse.\n",
    "\n",
    "The HMMER output formats should be more \"stable\" than the dbCAN format (which recently changed and hasn't been updated on their webserver).\n",
    "Ideally we want to support all three formats, but focussing on the HMMER ones.\n",
    "\n",
    "Because in our training we need to use lots of proteomes I'll be running this command using gnu parallel <https://www.gnu.org/software/parallel/>.\n",
    "Frankly, the documentation is confusion for this but the tutorial is fairly usable <https://www.gnu.org/software/parallel/parallel_tutorial.html>.\n",
    "They're also super aggressive with their citation reminders!\n",
    "\n",
    "Anyway, install with your favourite package manager.\n",
    "In the command we pipe a list of fasta files to parallel.\n",
    "It runs the provided command for each input line, substituting `{}` with the input filename, and `{/.}` with the input filename _sans_ extension or path.\n",
    "The final line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v4 is done\n",
      "v5 is done\n",
      "v6 is done\n",
      "v7 is done\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use all available CPUs by default\n",
    "# Replace number if you want to restrict CPU usage.\n",
    "NCPU=$(grep -c \"processor\" /proc/cpuinfo)\n",
    "\n",
    "# Replace this with the directory that your fastas are in.\n",
    "FASTA_DIR=\"20170531-trophic_prediction_fastas/fastas\"\n",
    "\n",
    "# Remove versions from this list as desired\n",
    "VERSIONS=\"v4 v5 v6 v7\"\n",
    "\n",
    "# Because v7 has different naming convention, use\n",
    "# associative array for mapping.\n",
    "declare -A DBPATHS\n",
    "DBPATHS[v4]=data/dbCAN-fam-HMMs.txt.v4\n",
    "DBPATHS[v5]=data/dbCAN-fam-HMMs.txt.v5\n",
    "DBPATHS[v6]=data/dbCAN-fam-HMMs.txt.v6\n",
    "DBPATHS[v7]=data/dbCAN-HMMdb-V7.txt\n",
    "\n",
    "for v in ${VERSIONS}; do\n",
    "    mkdir -p \"01-run_hmms/${v}\"\n",
    "    find \"${FASTA_DIR}\" -type f \\\n",
    "        | parallel -j ${NCPU} \"hmmscan --domtblout 01-run_hmms/${v}/{/.}_hmmer.csv ${DBPATHS[${v}]} {} > 01-run_hmms/${v}/{/.}_hmmer.txt\" \\\n",
    "        && echo \"${v} is done\"\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's done, now we need to get the special dbCAN formatted output.\n",
    "\n",
    "Note that if you are just running CATAStrophy, you can just use the domain table as input.\n",
    "\n",
    "Essentially this script just filters rows by some criteria (if alignment > 80aa, use E-value < 1e-5, otherwise use E-value < 1e-3; covered fraction of HMM > 0.3) and outputs a subset of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Remove versions from this list as desired\n",
    "VERSIONS=\"v4 v5 v6 v7\"\n",
    "\n",
    "for v in ${VERSIONS}; do\n",
    "    for f in $(ls 01-run_hmms/${v}/*_hmmer.csv | grep -v \"dbcan\"); do\n",
    "        f_noext=\"${f%.*}\"\n",
    "        bash ./data/hmmscan-parser.sh \"${f}\" > \"${f_noext}_dbcan.csv.tmp\" \\\n",
    "        && mv \"${f_noext}_dbcan.csv.tmp\" \"${f_noext}_dbcan.csv\"\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abisporus_varbisporusH97.v2.FilteredModels3.proteins_hmmer.csv\r\n",
      "Abisporus_varbisporusH97.v2.FilteredModels3.proteins_hmmer_dbcan.csv\r\n",
      "Abisporus_varbisporusH97.v2.FilteredModels3.proteins_hmmer.txt\r\n",
      "Abisporus_varburnettii.v2.FilteredModels1.proteins_hmmer.csv\r\n",
      "Abisporus_varburnettii.v2.FilteredModels1.proteins_hmmer_dbcan.csv\r\n",
      "Abisporus_varburnettii.v2.FilteredModels1.proteins_hmmer.txt\r\n",
      "Albugo_laibachii.ENA1.27.pep.all_hmmer.csv\r\n",
      "Albugo_laibachii.ENA1.27.pep.all_hmmer_dbcan.csv\r\n",
      "Albugo_laibachii.ENA1.27.pep.all_hmmer.txt\r\n",
      "Alternaria_alternata.Altal1.strainSRC1lrK2f.pep.all_hmmer.csv\r\n",
      "ls: write error\r\n"
     ]
    }
   ],
   "source": [
    "ls 01-run_hmms/v5/ | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#                                                                            --- full sequence --- -------------- this domain -------------   hmm coord   ali coord   env coord\r\n",
      "# target name        accession   tlen query name           accession   qlen   E-value  score  bias   #  of  c-Evalue  i-Evalue  score  bias  from    to  from    to  from    to  acc description of target\r\n",
      "#------------------- ---------- ----- -------------------- ---------- ----- --------- ------ ----- --- --- --------- --------- ------ ----- ----- ----- ----- ----- ----- ----- ---- ---------------------\r\n",
      "GH129.hmm            -            618 CCA21570             -            611   0.00079   12.3   0.0   1   1   3.4e-06    0.0012   11.7   0.0   490   571   345   423   339   430 0.88 -\r\n",
      "GH80.hmm             -             63 CCA21581             -           1335    0.0024   12.3   0.1   1   2      0.15        53   -1.6   0.0    30    48   237   255   234   258 0.89 -\r\n",
      "GH80.hmm             -             63 CCA21581             -           1335    0.0024   12.3   0.1   2   2   3.6e-05     0.013   10.0   0.0    15    43   899   927   890   932 0.88 -\r\n",
      "GH135.hmm            -            237 CCA19424             -            460    0.0029   11.8   0.0   1   1   1.5e-05    0.0053   10.9   0.0    79   123   292   335   285   352 0.82 -\r\n",
      "GT1.hmm              -            382 CCA19431             -            435   5.8e-16   53.9   0.2   1   1   4.5e-18     8e-16   53.5   0.2   123   379    44   336     2   339 0.71 -\r\n",
      "GT28.hmm             -            157 CCA19431             -            435   0.00041   14.6   0.1   1   1   4.2e-06   0.00076   13.7   0.1    78   146   251   315   223   323 0.83 -\r\n",
      "GT1.hmm              -            382 CCA19432             -            423   9.6e-16   53.2   0.1   1   1   6.9e-18   1.2e-15   52.9   0.1   191   379   116   324     6   327 0.73 -\r\n"
     ]
    }
   ],
   "source": [
    "!head 01-run_hmms/v5/Albugo_laibachii.ENA1.27.pep.all_hmmer.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# hmmscan :: search sequence(s) against a profile database\r\n",
      "# HMMER 3.2.1 (June 2018); http://hmmer.org/\r\n",
      "# Copyright (C) 2018 Howard Hughes Medical Institute.\r\n",
      "# Freely distributed under the BSD open source license.\r\n",
      "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n",
      "# query sequence file:             20170531-trophic_prediction_fastas/fastas/Albugo_laibachii.ENA1.27.pep.all.fasta\r\n",
      "# target HMM database:             data/dbCAN-fam-HMMs.txt.v5\r\n",
      "# per-dom hits tabular output:     01-run_hmms/v5/Albugo_laibachii.ENA1.27.pep.all_hmmer.csv\r\n",
      "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head 01-run_hmms/v5/Albugo_laibachii.ENA1.27.pep.all_hmmer.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GH38.hmm\t269\tCCA13903\t1025\t3.9e-75\t1\t269\t48\t349\t0.996282527881041\r\n",
      "CBM47.hmm\t128\tCCA13913\t1044\t2.3e-10\t6\t118\t764\t877\t0.875\r\n",
      "GT4.hmm\t160\tCCA13921\t458\t7.2e-06\t34\t157\t263\t383\t0.76875\r\n",
      "GH5.hmm\t275\tCCA13966\t770\t1.8e-29\t3\t239\t59\t574\t0.858181818181818\r\n",
      "CE2.hmm\t209\tCCA14218\t469\t5.6e-65\t1\t209\t201\t430\t0.995215311004785\r\n",
      "GH17.hmm\t311\tCCA14249\t419\t4.5e-19\t29\t306\t133\t374\t0.890675241157556\r\n",
      "CBM32.hmm\t124\tCCA14262\t583\t4.1e-09\t14\t109\t464\t563\t0.766129032258065\r\n",
      "GT31.hmm\t192\tCCA14287\t372\t4.9e-16\t50\t183\t111\t257\t0.692708333333333\r\n",
      "GH30.hmm\t417\tCCA14291\t682\t2.9e-106\t4\t374\t108\t506\t0.887290167865707\r\n",
      "GH72.hmm\t312\tCCA14303\t556\t7.5e-73\t6\t284\t58\t372\t0.891025641025641\r\n"
     ]
    }
   ],
   "source": [
    "!head 01-run_hmms/v5/Albugo_laibachii.ENA1.27.pep.all_hmmer_dbcan.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the HMM lengths\n",
    "\n",
    "because the HMMER plain text output doesn't contain the HMM length anywhere, I'll need to save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "from catas.parsers import split_hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regex = re.compile(r\"\\s+\")\n",
    "output = defaultdict(dict)\n",
    "\n",
    "VERSIONS = {\n",
    "    \"v4\": \"data/dbCAN-fam-HMMs.txt.v4\",\n",
    "    \"v5\": \"data/dbCAN-fam-HMMs.txt.v5\",\n",
    "    \"v6\": \"data/dbCAN-fam-HMMs.txt.v6\",\n",
    "    \"v7\": \"data/dbCAN-HMMdb-V7.txt\",\n",
    "}\n",
    "    \n",
    "for version, db in VERSIONS.items():\n",
    "    with open(db) as handle:\n",
    "        current_name = None\n",
    "        for line in handle:\n",
    "            if line.startswith(\"NAME\"):\n",
    "                line = regex.split(line)\n",
    "                current_name = split_hmm(line[1])\n",
    "            elif line.startswith(\"LENG\"):\n",
    "                line = regex.split(line, maxsplit=1)\n",
    "                if current_name is None:\n",
    "                    print(line)\n",
    "                    raise\n",
    "\n",
    "                output[version][current_name] = int(line[1])\n",
    "                current_name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll save that as a JSON file in the catas data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in VERSIONS:\n",
    "    with open(\"../catas/data/{}-{}-hmm_lengths.json\".format(version, TODAY), \"w\") as handle:\n",
    "        json.dump(output[version], handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from subprocess import Popen\n",
    "from subprocess import PIPE\n",
    "\n",
    "import catas.data\n",
    "\n",
    "fasta_file = catas.data.sample_fasta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for version, db in VERSIONS.items():\n",
    "    command = [\n",
    "        \"hmmscan\",\n",
    "        \"--domtblout\",\n",
    "        \"../catas/data/{}-{}-test_hmmer.csv\".format(version, TODAY),\n",
    "        db,\n",
    "        fasta_file\n",
    "        ]\n",
    "    call = Popen(command, stdout=PIPE)\n",
    "    stdout, stderr = call.communicate()\n",
    "\n",
    "    with open(\"../catas/data/{}-{}-test_hmmer.txt\".format(version, TODAY), \"wb\") as handle:\n",
    "        handle.write(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in VERSIONS:\n",
    "    command = [\n",
    "        \"bash\",\n",
    "        \"./data/hmmscan-parser.sh\",\n",
    "        \"../catas/data/{}-{}-test_hmmer.csv\".format(version, TODAY)\n",
    "        ]\n",
    "    call = Popen(command, stdout=PIPE)\n",
    "    stdout, stderr = call.communicate()\n",
    "    \n",
    "    with open(\"../catas/data/{}-{}-test_dbcan.csv\".format(version, TODAY), \"wb\") as handle:\n",
    "        handle.write(stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
